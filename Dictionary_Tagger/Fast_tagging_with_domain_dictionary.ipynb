{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Load in the Raw_Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load in the training corpus\n",
    "\n",
    "\n",
    "\n",
    "# ========== Raw_Corpus.txt ==========\n",
    "with open(\"Raw_Corpus.txt\", 'r', encoding = 'utf-8') as f:\n",
    "    training_corpus = f.readlines()\n",
    "\n",
    "# print(training_corpus[0:5])\n",
    "# print(len(training_corpus))\n",
    "# print()\n",
    "\n",
    "\n",
    "# remove some specical objects \n",
    "\n",
    "import re\n",
    "\n",
    "training_corpus = str(training_corpus)\n",
    "training_corpus = re.sub(r\"[^a-zA-Z0-9.?! ]+\", \"\", training_corpus)\n",
    "training_corpus = training_corpus.lower()\n",
    "print(training_corpus[0:5])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1,2 Explore the Part-of-Speech with 'stanza'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turns out we didn't use this in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanza is the NLP model from Corenlp \n",
    "\n",
    "# here we use it to give POS of the words \n",
    "\n",
    "# !pip install stanza\n",
    "# import stanza\n",
    "# stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 07:37:23 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2021-10-25 07:37:23 INFO: Use device: cpu\n",
      "2021-10-25 07:37:23 INFO: Loading: tokenize\n",
      "2021-10-25 07:37:23 INFO: Loading: pos\n",
      "2021-10-25 07:37:23 INFO: Loading: lemma\n",
      "2021-10-25 07:37:23 INFO: Loading: depparse\n",
      "2021-10-25 07:37:23 INFO: Loading: sentiment\n",
      "2021-10-25 07:37:24 INFO: Loading: constituency\n",
      "2021-10-25 07:37:24 INFO: Loading: ner\n",
      "2021-10-25 07:37:25 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# using stanza\n",
    "\n",
    "import stanza\n",
    "# stanza.download('en') # download English model\n",
    "nlp = stanza.Pipeline('en') # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ADP\n",
      "this DET\n",
      "longitudin ADJ\n",
      "study NOUN\n",
      "we PRON\n",
      "tested VERB\n",
      "the DET\n",
      "hypothesis NOUN\n",
      "that SCONJ\n",
      "cows NOUN\n",
      "that PRON\n",
      "are AUX\n",
      "lame ADJ\n",
      "around ADP\n",
      "dryoff NOUN\n",
      "are AUX\n",
      "at ADP\n",
      "increased VERB\n",
      "risk NOUN\n",
      "of ADP\n",
      "transition NOUN\n",
      "diseases NOUN\n",
      "td NOUN\n",
      "including VERB\n",
      "metritis ADJ\n",
      "subclinica ADJ\n",
      "ketosis NOUN\n",
      "sck NOUN\n",
      "retained VERB\n",
      "fetal ADJ\n",
      "membranes NOUN\n",
      "hypocalcem ADJ\n",
      "or CCONJ\n",
      "displaced VERB\n",
      "abomasum NOUN\n",
      ". PUNCT\n",
      "we PRON\n",
      "also ADV\n",
      "hypothesiz VERB\n",
      "that SCONJ\n",
      "the DET\n",
      "relationsh NOUN\n",
      "between ADP\n",
      "lameness NOUN\n",
      "and CCONJ\n",
      "td NOUN\n",
      "would AUX\n",
      "be AUX\n",
      "mediated VERB\n",
      "through ADP\n",
      "reduced VERB\n",
      "feeding NOUN\n",
      "time NOUN\n",
      ". PUNCT\n",
      "we PRON\n",
      "enrolled VERB\n",
      "461 NUM\n",
      "cows NOUN\n",
      "at ADP\n",
      "9 NUM\n",
      "wk NOUN\n",
      "before ADP\n",
      "their PRON\n",
      "expected VERB\n",
      "calving NOUN\n",
      "date NOUN\n",
      "on ADP\n",
      "6 NUM\n",
      "commercial ADJ\n",
      "freestall ADJ\n",
      "farms NOUN\n",
      "in ADP\n",
      "the DET\n",
      "lower ADJ\n",
      "fraser NOUN\n",
      "valley NOUN\n",
      "british ADJ\n",
      "columbia PROPN\n",
      "canada PROPN\n",
      ". PUNCT\n",
      "cows NOUN\n",
      "were AUX\n",
      "gaitscored ADJ\n",
      "weekly ADV\n",
      "using VERB\n",
      "a DET\n",
      "scale NOUN\n",
      "of ADP\n",
      "1 NUM\n",
      "to ADP\n",
      "5 NUM\n",
      ". PUNCT\n",
      "lameness NOUN\n",
      "status NOUN\n",
      "was AUX\n",
      "classified VERB\n",
      "based VERB\n",
      "on ADP\n",
      "consecutiv ADJ\n",
      "gait NOUN\n",
      "scores NOUN\n",
      "as ADP\n",
      "lame ADJ\n",
      "2 NUM\n",
      "consecutiv ADJ\n",
      "gait NOUN\n",
      "scores NOUN\n",
      "3 NUM\n",
      "or CCONJ\n",
      "1 NUM\n",
      "score NOUN\n",
      "4 NUM\n",
      "or CCONJ\n",
      "sound NOUN\n",
      "2 NUM\n",
      "consecutiv ADJ\n",
      "gait NOUN\n",
      "scores NOUN\n",
      "2 NUM\n",
      ". PUNCT\n",
      "lameness NOUN\n",
      "status NOUN\n",
      "was AUX\n",
      "summarized VERB\n",
      "as ADP\n",
      "1 NUM\n",
      "lameness NOUN\n",
      "at ADP\n",
      "dryoff ADJ\n",
      "sound NOUN\n",
      "or CCONJ\n",
      "lame ADJ\n",
      "2 NUM\n",
      "lameness NOUN\n",
      "group NOUN\n",
      "always ADV\n",
      "sound VERB\n",
      "sound NOUN\n",
      "on ADP\n",
      "all DET\n",
      "visits NOUN\n",
      "chronicall ADV\n",
      "lame ADJ\n",
      "lame ADJ\n",
      "on ADP\n",
      "all DET\n",
      "visits NOUN\n",
      "and CCONJ\n",
      "other ADJ\n",
      "changed VERB\n",
      "from ADP\n",
      "sound NOUN\n",
      "to ADP\n",
      "lame ADJ\n",
      "or CCONJ\n",
      "vice NOUN\n",
      "versa NOUN\n",
      "and CCONJ\n",
      "3 NUM\n",
      "proportion NOUN\n",
      "of ADP\n",
      "weeks NOUN\n",
      "lame ADJ\n",
      "during ADP\n",
      "the DET\n",
      "dry ADJ\n",
      "period NOUN\n",
      ". PUNCT\n",
      "body NOUN\n",
      "condition NOUN\n",
      "scores NOUN\n",
      "were AUX\n",
      "recorded VERB\n",
      "at ADP\n",
      "dryoff NOUN\n",
      "and CCONJ\n",
      "at ADP\n",
      "calving NOUN\n",
      "and CCONJ\n",
      "collective ADV\n",
      "used VERB\n",
      "to PART\n",
      "calculate VERB\n",
      "change NOUN\n",
      "in ADP\n",
      "body NOUN\n",
      "condition NOUN\n",
      "for ADP\n",
      "each DET\n",
      "cow NOUN\n",
      ". PUNCT\n",
      "a DET\n",
      "subsample NOUN\n",
      "of ADP\n",
      "cows NOUN\n",
      "n ADP\n",
      "159 NUM\n",
      "was AUX\n",
      "evaluated VERB\n",
      "for ADP\n",
      "feeding VERB\n",
      "time NOUN\n",
      "once ADV\n",
      "a DET\n",
      "week NOUN\n",
      "during ADP\n",
      "the DET\n",
      "dry ADJ\n",
      "period NOUN\n",
      ". PUNCT\n",
      "all DET\n",
      "cows NOUN\n",
      "were AUX\n",
      "evaluated VERB\n",
      "for ADP\n",
      "sck DET\n",
      "positive ADJ\n",
      "hydroxybut NOUN\n",
      "1.2 NUM\n",
      "mmoll NOUN\n",
      "and CCONJ\n",
      "metritis ADJ\n",
      "positive ADJ\n",
      "foul NOUN\n",
      "smell NOUN\n",
      "redbrown ADV\n",
      "watery ADJ\n",
      "vaginal ADJ\n",
      "discharge NOUN\n",
      "every DET\n",
      "3 NUM\n",
      "to ADP\n",
      "4 NUM\n",
      "d NOUN\n",
      "between ADP\n",
      "d PROPN\n",
      "3 NUM\n",
      "and CCONJ\n",
      "17 NUM\n",
      "after SCONJ\n",
      "calving NOUN\n",
      ". PUNCT\n",
      "we PRON\n",
      "retrieved VERB\n",
      "data NOUN\n",
      "on ADP\n",
      "treatment NOUN\n",
      "of ADP\n",
      "retained VERB\n",
      "fetal ADJ\n",
      "membranes NOUN\n",
      "hypocalcem ADJ\n",
      "and CCONJ\n",
      "displaced VERB\n",
      "abomasum NOUN\n",
      "during ADP\n",
      "the DET\n",
      "first ADJ\n",
      "17 NUM\n",
      "d NOUN\n",
      "after SCONJ\n",
      "calving VERB\n",
      "cow NOUN\n",
      "parity NOUN\n",
      "and CCONJ\n",
      "milk NOUN\n",
      "production NOUN\n",
      "in ADP\n",
      "the DET\n",
      "previous ADJ\n",
      "lactation NOUN\n",
      "from ADP\n",
      "farm NOUN\n",
      "records NOUN\n",
      ". PUNCT\n",
      "we PRON\n",
      "created VERB\n",
      "a DET\n",
      "binary ADJ\n",
      "variable ADJ\n",
      "td NOUN\n",
      "any DET\n",
      "of ADP\n",
      "sck NOUN\n",
      "metritis NOUN\n",
      "retained VERB\n",
      "fetal ADJ\n",
      "membranes NOUN\n",
      "hypocalcem ADJ\n",
      "or CCONJ\n",
      "displaced VERB\n",
      "abomasum NOUN\n",
      "to PART\n",
      "differenti VERB\n",
      "between ADP\n",
      "healthy ADJ\n",
      "cows NOUN\n",
      "and CCONJ\n",
      "cows NOUN\n",
      "that PRON\n",
      "developed VERB\n",
      "td NOUN\n",
      ". PUNCT\n",
      "lameness NOUN\n",
      "at ADP\n",
      "dryoff NOUN\n",
      "was AUX\n",
      "associated VERB\n",
      "with ADP\n",
      "the DET\n",
      "occurrence NOUN\n",
      "of ADP\n",
      "metritis NOUN\n",
      "and CCONJ\n",
      "td NOUN\n",
      "but CCONJ\n",
      "not PART\n",
      "with ADP\n",
      "sck NOUN\n",
      ". PUNCT\n",
      "cows NOUN\n",
      "that PRON\n",
      "were AUX\n",
      "chronicall ADV\n",
      "lame ADJ\n",
      "and CCONJ\n",
      "cows NOUN\n",
      "that PRON\n",
      "had VERB\n",
      "an DET\n",
      "increased VERB\n",
      "proportion NOUN\n",
      "of ADP\n",
      "weeks NOUN\n",
      "lame ADJ\n",
      "during ADP\n",
      "the DET\n",
      "dry ADJ\n",
      "period NOUN\n",
      "had VERB\n",
      "higher ADJ\n",
      "occurrence NOUN\n",
      "of ADP\n",
      "metritis NOUN\n",
      "and CCONJ\n",
      "td. NOUN\n",
      "lameness NOUN\n",
      "was AUX\n",
      "also ADV\n",
      "associated VERB\n",
      "with ADP\n",
      "reduced VERB\n",
      "feeding NOUN\n",
      "time NOUN\n",
      "which PRON\n",
      "in ADP\n",
      "turn NOUN\n",
      "was AUX\n",
      "associated VERB\n",
      "with ADP\n",
      "increased VERB\n",
      "likelihood NOUN\n",
      "of ADP\n",
      "sck NOUN\n",
      "and CCONJ\n",
      "td NOUN\n",
      "but CCONJ\n",
      "not PART\n",
      "with ADP\n",
      "metritis NOUN\n",
      ". PUNCT\n",
      "lameness NOUN\n",
      "was AUX\n",
      "not PART\n",
      "associated VERB\n",
      "with ADP\n",
      "change NOUN\n",
      "in ADP\n",
      "body NOUN\n",
      "condition NOUN\n",
      "however ADV\n",
      "cows NOUN\n",
      "that PRON\n",
      "lost VERB\n",
      "body NOUN\n",
      "condition NOUN\n",
      "score NOUN\n",
      "during ADP\n",
      "the DET\n",
      "dry ADJ\n",
      "period NOUN\n",
      "had AUX\n",
      "increased VERB\n",
      "odds NOUN\n",
      "of SCONJ\n",
      "developing VERB\n",
      "sck NOUN\n",
      "metritis NOUN\n",
      "and CCONJ\n",
      "td. NOUN\n",
      "change NOUN\n",
      "in ADP\n",
      "body NOUN\n",
      "condition NOUN\n",
      "was AUX\n",
      "highly ADV\n",
      "associated VERB\n",
      "with ADP\n",
      "body NOUN\n",
      "condition NOUN\n",
      "score NOUN\n",
      "at ADP\n",
      "dryoff NOUN\n",
      ". PUNCT\n",
      "these DET\n",
      "results NOUN\n",
      "suggest VERB\n",
      "that SCONJ\n",
      "associatio NOUN\n",
      "between ADP\n",
      "lameness NOUN\n",
      "and CCONJ\n",
      "td NOUN\n",
      "is AUX\n",
      "partially ADV\n",
      "mediated VERB\n",
      "through ADP\n",
      "reduced VERB\n",
      "feeding NOUN\n",
      "time NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# try out printing verbs \n",
    "\n",
    "# doc = nlp('Barack Obama was born in Hawaii, which is a nice place to take vacation')\n",
    "# training_corpus = training_corpus[0:1000]\n",
    "doc = nlp(training_corpus)\n",
    "\n",
    "word_pos = []\n",
    "word_text = []\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        word_pos.append(word.pos)\n",
    "        word_text.append(word.text)\n",
    "        \n",
    "        print(word.text[0:10], word.pos[0:10])\n",
    "        # print(type(word_pos))\n",
    "        # print(len(word_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  431\n"
     ]
    }
   ],
   "source": [
    "# see the len\n",
    "\n",
    "print(\"length: \", len(word_text))\n",
    "words_corpus = word_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform the pos into number in order to add all labels\n",
    "\n",
    "### change the 'PUNCT' into -10, we will erase them from excel to show this is the end of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 1000,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 1000,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 10000,\n",
       " 0,\n",
       " 1000,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the pos into number in order to add all labels\n",
    "# change the 'PUNCT' into -10, so we can erase them from excel \n",
    "\n",
    "\n",
    "# ADJ: 1000, VERB: 10000\n",
    "\n",
    "for n, i in enumerate(word_pos):\n",
    "    if i == 'ADJ':\n",
    "        word_pos[n] = 1000\n",
    "    elif i == 'VERB':\n",
    "        word_pos[n] = 10000\n",
    "    elif i == 'PUNCT':\n",
    "        word_pos[n] = -10\n",
    "    else:\n",
    "        word_pos[n] = 0\n",
    "\n",
    "word_pos[0:10]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, Processing the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in domian list of dictionary: nutrition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few items of the training corpus list\n",
      "[\"['start\", 'nefa', 'nfc', 'lipoproteins', 'ketones', 'fat', 'straw', 'lactic', 'digestibility', 'amino', 'triglycerides', 'acid', 'vitamins', 'nonfiber', 'carbohydrates', 'starch', 'maize', 'concentrate', 'diet', 'hydroxybutyrate', 'triacylglycerol', 'nonfibrous', 'carbohydrate', 'niacin', 'glucose', 'diets', 'lipid', 'ndf', 'protein', 'energy', 'macrominerals', 'calcium', 'phosphorus', 'magnesium', 'sodium', 'potassium', 'chloride', 'sulfur', 'dcad', 'microminerals', 'iron', 'manganese', 'copper', 'iodine', 'zinc', 'cobalt', 'fluoride', 'selenium', 'modifier', 'dmi', 'dry', 'matter', 'intake', 'vit', 'vitamine', 'e', 'acetate', 'fiber', 'ketone', 'lipogenesis', 'propionate', 'trigyceride', 'volatile', 'fatty', 'acids', 'vfa', 'antibiotic', 'ca', 'p', 'na', 'nutrition', 'nonesterified', 'crude', 'non-fiber', 'carbohydrate', 'corn', 'silage', 'pasture', 'hay', 'crop', 'grass', 'water', 'ration', 'monensin', 'legume', 'oats', 'nutrient', 'feeds', 'feeding', 'nutrients', 'dry', 'feed', 'soybean', 'grains', 'grain', 'cp', 'rdp', 'rup', 'mp', 'ne', 'ndf', 'd', 'e', 'net', 'energy', 'neutral', 'detergent', 'fiber', 'trace', 'mineral', 'salts', 'salt', \"',\", \"'end']\"]\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "# domian list of dictionary: nutrition \n",
    "\n",
    "with open(\"Nutrition_Dictionary.txt\", 'r', encoding = 'utf-8') as f:\n",
    "    nutrition_dict = f.readlines()\n",
    "\n",
    "# process the dict \n",
    "def process_dict(dict1):\n",
    "    # dict1 = str(dict1)\n",
    "    dict1 = str(dict1)\n",
    "    dict1 = dict1.strip().replace('\\\\n', '')\n",
    "    dict1 = dict1.lower()\n",
    "    dict1 = dict1.split(' ')\n",
    "    return dict1\n",
    "\n",
    "\n",
    "print(f\"A few items of the training corpus list\")\n",
    "nutrition_dict = process_dict(nutrition_dict)\n",
    "print(nutrition_dict)\n",
    "print(len(nutrition_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in domian list of dictionary: diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['start\", 'milk', 'subclinical', 'placenta', 'abomasums', 'hypocalcaemia', 'delayed', 'conception', 'leukosis', 'overconditioning', 'immunosuppression', 'stressful', 'dystocia', 'risk', 'infertility', 'antiinflammatory', 'disease', 'diseases', 'abomasum', 'stress', 'inflammation', 'fever', 'ketosis', 'abomasal', 'displacement', 'rad', 'lad', 'clinical', 'cm', 'metritis', 'mastitis', 'lameness', 'hypomagnesemia', 'retained', 'vaginal', 'discharge', 'assistance', 'acidosis', 'metritis', 'diarrhea', 'displaced', 'metabolic', 'disorders', 'bluetongue', 'bvd', 'diphtheria', 'pneumonia', 'fog', 'fever', 'ibr', 'tb', 'thrombosis', 'trypanosomosis', 'acetonaemia', 'liver', 'acidosis', 'blackleg', 'bloat', 'coccidiosis', 'johnes', 'deficiency', 'diarrhoea', 'scour', 'poisoning', 'abortion', 'culled', 'cull', 'bvd', 'retained', 'fetal', 'membranes', 'haemorrhagic', 'scald', 'ringowrm', 'ulcer', 'edema', 'sara', \"end']\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# domian list of dictionary: diseases\n",
    "\n",
    "with open(\"Diseases_Dictionary.txt\", 'r', encoding = 'utf-8') as f:\n",
    "    diseases_dict = f.readlines()\n",
    "\n",
    "diseases_dict = process_dict(diseases_dict)\n",
    "print(diseases_dict)\n",
    "\n",
    "len(diseases_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in domian list of dictionary: period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['autumn\", 'spring', 'summer', 'winter', 'breeding', 'pregnant', 'early', 'fresh', 'after', 'transition', 'period', 'postpartum', 'postcalving', 'lactating', 'lactation', 'prepartum', 'beginning', 'during', 'calving', 'culling', 'drying', 'day', 'days', 'when', 'pregnancy', 'stage', 'parturition', 'early', 'mid', 'late', 'dry', 'throughout', 'age', 'era', 'time', 'year', 'cycle', 'date', 'while', 'duration', 'length', 'primigravid', 'insemination', 'parturition', 'initiation', 'week', 'weeks', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', \"ten',\", \"'',\", \"'']\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# domian list of dictionary: period\n",
    "\n",
    "with open(\"Period_Dictionary.txt\", 'r', encoding = 'utf-8') as f:\n",
    "    period_dict = f.readlines()\n",
    "\n",
    "period_dict = process_dict(period_dict)\n",
    "print(period_dict)\n",
    "\n",
    "len(period_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tagging with gensim(a NLP package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag the nutrition words as 1, otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag the nutrition words as 1, otherwise 0\n",
    "\n",
    "nutrition_dict = [nutrition_dict]\n",
    "dct_nutri = Dictionary(nutrition_dict)\n",
    "nutrition_tag = dct_nutri.doc2idx(words_corpus)\n",
    "\n",
    "def process_tagging_nutrition(tagging):\n",
    "    \n",
    "    for n, i in enumerate(tagging):\n",
    "        if i == -1:\n",
    "            tagging[n] = 0\n",
    "        else: \n",
    "            tagging[n] = 1\n",
    "            \n",
    "    return tagging\n",
    "\n",
    "nutrition_tag = process_tagging_nutrition(nutrition_tag)\n",
    "\n",
    "nutrition_tag[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag the diseases words as 10, otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag the diseases words as 10, otherwise 0\n",
    "\n",
    "diseases_dict = [diseases_dict]\n",
    "dct_diseases = Dictionary(diseases_dict)\n",
    "diseases_tag = dct_diseases.doc2idx(words_corpus)\n",
    "\n",
    "def process_tagging_diseases(tagging):\n",
    "    \n",
    "    for n, i in enumerate(tagging):\n",
    "        if i == -1:\n",
    "            tagging[n] = 0\n",
    "        else: \n",
    "            tagging[n] = 10\n",
    "            \n",
    "    return tagging\n",
    "\n",
    "diseases_tag = process_tagging_diseases(diseases_tag)\n",
    "\n",
    "diseases_tag[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag the period words as 100, otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 100,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 100,\n",
       " 100,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag the period words as 100, otherwise 0\n",
    "\n",
    "period_dict = [period_dict]\n",
    "dct_period = Dictionary(period_dict)\n",
    "period_tag = dct_period.doc2idx(words_corpus)\n",
    "\n",
    "def process_tagging_period(tagging):\n",
    "    \n",
    "    for n, i in enumerate(tagging):\n",
    "        if i == -1:\n",
    "            tagging[n] = 0\n",
    "        else: \n",
    "            tagging[n] = 100\n",
    "            \n",
    "    return tagging\n",
    "\n",
    "period_tag = process_tagging_period(period_tag)\n",
    "\n",
    "period_tag[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the overall tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 100,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 100,\n",
       " 100,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The overall tagging \n",
    "\n",
    "sum_tag = []\n",
    "for (item1, item2, item3) in zip(nutrition_tag, diseases_tag, period_tag):\n",
    "    sum_tag.append(item1+item2+item3)\n",
    "\n",
    "sum_tag[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat the tagging and pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000,\n",
       " 1,\n",
       " 100,\n",
       " -10,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 100,\n",
       " 100,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 0,\n",
       " -10,\n",
       " 0,\n",
       " 0,\n",
       " 1000,\n",
       " 0,\n",
       " 10000,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -10,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 10000,\n",
       " 10000,\n",
       " 0,\n",
       " 1000,\n",
       " 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat the tagging and pos\n",
    "\n",
    "tag_pos = []\n",
    "for (item1, item2) in zip(sum_tag, word_pos):\n",
    "        tag_pos.append(item1 + item2)\n",
    "    \n",
    "tag_pos[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign the corresponding label \n",
    "\n",
    "### with B-NUT\n",
    "\n",
    "### with B-DIS\n",
    "\n",
    "### with B-PER\n",
    "\n",
    "### with ADJ\n",
    "\n",
    "### with VERB\n",
    "\n",
    "### with PUNCT\n",
    "\n",
    "### with O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VERB',\n",
       " 'B-NUT',\n",
       " 'B-PER',\n",
       " 'PUNCT',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'B-PER',\n",
       " 'B-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'PUNCT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'PUNCT',\n",
       " 'B-DIS',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign the corresponding label \n",
    "\n",
    "for n,i in enumerate(tag_pos): \n",
    "    if i == 1 or i == 1001 or i == 10001:\n",
    "        tag_pos[n] = 'B-NUT'\n",
    "    elif i == 10 or i == 1010 or i == 10010:\n",
    "        tag_pos[n] = 'B-DIS'\n",
    "    elif i == 100 or i == 1100 or i == 10100:\n",
    "        tag_pos[n] = 'B-PER'\n",
    "    elif i == 1000:\n",
    "        tag_pos[n] = 'ADJ'\n",
    "    elif i == 10000:\n",
    "        tag_pos[n] = 'VERB'\n",
    "    elif i == -10:\n",
    "        tag_pos[n] = 'PUNCT'\n",
    "    else:\n",
    "        tag_pos[n] = 'O'\n",
    "        \n",
    "tag_pos[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the format to BIO tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'B-DIS',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'B-DIS',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'B-DIS',\n",
       " 'I-DIS',\n",
       " 'I-DIS',\n",
       " 'O',\n",
       " 'B-DIS',\n",
       " 'I-DIS',\n",
       " 'I-DIS',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'B-DIS',\n",
       " 'I-DIS',\n",
       " 'PUNCT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DIS',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'B-NUT',\n",
       " 'B-PER',\n",
       " 'PUNCT',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'O',\n",
       " 'PUNCT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'PUNCT',\n",
       " 'B-DIS',\n",
       " 'O',\n",
       " 'O',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'O',\n",
       " 'ADJ',\n",
       " 'O']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the format to BIO tagging \n",
    "\n",
    "for idx in range(0, len(tag_pos) - 1):\n",
    "    \n",
    "    # if there is a consuquential BIO words\n",
    "    if tag_pos[idx] == tag_pos[idx + 1]:\n",
    "        \n",
    "        # for nutrition\n",
    "        if tag_pos[idx] == 'B-NUT':\n",
    "            tag_pos[idx + 1] = 'I-NUT'\n",
    "            if tag_pos[idx + 2] == 'B-NUT':\n",
    "                tag_pos[idx + 2] = 'I-NUT'\n",
    "                \n",
    "        # for diseases\n",
    "        if tag_pos[idx] == 'B-DIS':\n",
    "            tag_pos[idx + 1] = 'I-DIS'\n",
    "            if tag_pos[idx + 2] == 'B-DIS':\n",
    "                tag_pos[idx + 2] = 'I-DIS'\n",
    "                \n",
    "        # for period\n",
    "        if tag_pos[idx] == 'B-PER':\n",
    "            tag_pos[idx + 1] = 'I-PER'\n",
    "            if tag_pos[idx + 2] == 'B-PER':\n",
    "                tag_pos[idx + 2] = 'I-PER'\n",
    "\n",
    "        \n",
    "tag_pos[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the length \n",
    "\n",
    "len(tag_pos) == len(words_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4, Output the list to excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as words, labels and pos\n",
    "\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "df = pd.DataFrame([words_corpus,tag_pos])\n",
    "\n",
    "# transpose the columns and rows\n",
    "d_f = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Name of the output excel  ==========\n",
    "\n",
    "d_f.to_excel('Tagged_and_Pos_corpus_2021_10_25.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5, The following steps are conduct in the excel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1, The POS(VERB, ADJ) was plan to help finding the entity, all change to 'O' if not using them\n",
    "\n",
    "\n",
    "\n",
    "2, The POS(PUNCT) is used to find the end of a sentence, delete 'PUNCT' and '.' from excel to distinguish the end of each sentence\n",
    "\n",
    "\n",
    "\n",
    "3, Finally, it is better to check and eidt the word one by one to make sure the tagging is 100% correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
